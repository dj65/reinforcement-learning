{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1bd2d60-05e6-4ba4-8e13-8feeeb9d51e7",
   "metadata": {},
   "source": [
    "# Use this Notebook to watch training as it is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f935b1-6863-4ccb-8c7f-d648eb31de0c",
   "metadata": {},
   "source": [
    "#### To use this notebook only change one line as directed below, and then execute all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "305fbe05-28cc-44dd-a1f9-19da85dfc723",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install tqdm torch tensorboard -e ./PyGame-Learning-Environment/PyGame-Learning-Environment-master -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0be4e63-df6e-4b58-85ca-9636481f8e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import ple\n",
    "from IPython.display import clear_output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778aa386-94f6-454c-9c37-2f5b299025e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Determines the best action to take given a state. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_feature_len: int, \n",
    "                 out_feature_len: int,                 \n",
    "                 hidden_neuron_len: int, \n",
    "                 learning_rate:float,\n",
    "                 model_path: str = None\n",
    "                ):\n",
    "        super().__init__()        \n",
    "        self.linear1 = torch.nn.Linear(in_feature_len, hidden_neuron_len)\n",
    "        self.linear2 = torch.nn.Linear(hidden_neuron_len, out_feature_len)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = torch.nn.ReLU()(self.linear1(x))\n",
    "        x = torch.nn.Softmax(dim=-1)(self.linear2(x))      \n",
    "        return x\n",
    "\n",
    "def try_load(func: callable) -> any:\n",
    "    while True:\n",
    "        try:\n",
    "            return func()\n",
    "        except EOFError as e:\n",
    "            print(e)\n",
    "            print('Reloading')\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "            print('Reloading')\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "            print(\"Try running PPO_From_Scratch.ipynb\")\n",
    "            print()\n",
    "            print(\"Trying again in 10 seconds\")\n",
    "            time.sleep(10)\n",
    "            clear_output()\n",
    "            \n",
    "        time.sleep(1)\n",
    "\n",
    "def _load_model(\n",
    "    in_feature_len: int, \n",
    "    out_feature_len: int, \n",
    "    hidden_neuron_len: int, \n",
    "    learning_rate: float\n",
    "):\n",
    "    policy = PolicyModel(\n",
    "        in_feature_len = in_feature_len, \n",
    "        out_feature_len = out_feature_len, \n",
    "        hidden_neuron_len = hidden_neuron_len, \n",
    "        learning_rate = learning_rate,\n",
    "    )\n",
    "    policy.load_state_dict(torch.load(MODEL_PATH, weights_only=True))\n",
    "    policy.double()\n",
    "    policy.cpu()\n",
    "    return policy\n",
    "\n",
    "def _print_summary(\n",
    "    highest_score: int, \n",
    "    score: int, \n",
    "    hit: int,\n",
    "    miss: int,\n",
    "    frame_i: int,\n",
    "    reload_frames: int,\n",
    "    reload_threshold_frames: int,\n",
    "    max_frames: int\n",
    "):\n",
    "    print(f\"Highest Score: {highest_score}\")    \n",
    "    print(f\"Score: {score}\")\n",
    "    print(f\"Hit: {hit}\")\n",
    "    print(f\"Miss: {miss}\")\n",
    "    print(f\"Frame: {frame_i}\")\n",
    "    print(f\"Frames until model reload: {reload_frames} of {reload_threshold_frames}\")\n",
    "    print(f\"Frames until forced new game: {frame_i} of {max_frames}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dae3f4-91a3-4c7c-a7bc-f3c7b234952f",
   "metadata": {},
   "source": [
    "## Remove comments only for the game of choice\n",
    "NOTE: Ensure that the game is running, or has already run, in the [PPO_From_Scratch.ipynb](PPO_From_Scratch.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f0de96c-4f5f-4f6a-914b-4691b5d40983",
   "metadata": {},
   "outputs": [],
   "source": [
    "game = ple.games.Catcher(width=64 *8, height=64*8, init_lives=35); MODEL_PATH = 'catcher.model'\n",
    "#game = ple.games.flappybird.FlappyBird();  MODEL_PATH = 'flappybird.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b782b816-5a4a-4e8a-b9b7-44554336e816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest Score: 10.0\n",
      "Score: 10.0\n",
      "Hit: 11\n",
      "Miss: 1\n",
      "Frame: 423\n",
      "Frames until model reload: 423 of 1000\n",
      "Frames until forced new game: 423 of 9000\n",
      "\n",
      "Execution stopped by user\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "FPS = 30\n",
    "ACTIONS = [None] + list(game.actions.values())\n",
    "p = ple.PLE(game, fps=FPS, display_screen=True, force_fps=False)\n",
    "p.init()\n",
    "\n",
    "load_config = lambda: torch.load(f\"{MODEL_PATH}.config\")\n",
    "config = try_load(load_config)\n",
    "\n",
    "load_min_max = lambda: torch.load(f\"{MODEL_PATH}.min-max\", weights_only=False)\n",
    "min_max = try_load(load_min_max)\n",
    "\n",
    "load_model = lambda: _load_model(\n",
    "    in_feature_len = min_max['min'].shape[0], \n",
    "    out_feature_len = len(ACTIONS), \n",
    "    hidden_neuron_len = int(config['POLICY_HIDDEN_LEN']), \n",
    "    learning_rate = float(config['POLICY_LR']),\n",
    ")\n",
    "policy = try_load(load_model)\n",
    "\n",
    "MAX_MINUTES_PER_GAME = 5\n",
    "RELOAD_THRESHOLD_FRAMES = 1000\n",
    "SCREEN_DELAY_SECONDS = 3\n",
    "highest_score = 0\n",
    "hit = 0\n",
    "miss = 0\n",
    "global_frame_i = 0\n",
    "last_reload = 0\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        p.reset_game()\n",
    "        for frame_i in range(MAX_MINUTES_PER_GAME * 60 * FPS):\n",
    "            clear_output(wait=True)\n",
    "            if p.score() > highest_score:\n",
    "                highest_score = p.score()\n",
    "            \n",
    "            if p.game_over():\n",
    "                print(\"\\nGame Over. Resetting.\")\n",
    "                hit = 0\n",
    "                miss = 0\n",
    "                p.reset_game()\n",
    "                break\n",
    "        \n",
    "            state = list(p.getGameState().values())\n",
    "            state = (state - min_max['min'])/(min_max['max'] - min_max['min'])\n",
    "            one_hot_action = policy(torch.tensor(state)).detach()\n",
    "            action_index = int(np.argmax(one_hot_action))\n",
    "            action = ACTIONS[action_index]\n",
    "\n",
    "            reward = p.act(action)\n",
    "            if reward > 0:\n",
    "                hit += 1\n",
    "            elif reward == -1:\n",
    "                miss += 1\n",
    "\n",
    "            _print_summary(\n",
    "                highest_score = highest_score, \n",
    "                score = p.score(), \n",
    "                hit = hit,\n",
    "                miss = miss,\n",
    "                frame_i = frame_i,\n",
    "                reload_frames = global_frame_i - last_reload,\n",
    "                reload_threshold_frames = RELOAD_THRESHOLD_FRAMES,\n",
    "                max_frames = MAX_MINUTES_PER_GAME * 60 * FPS\n",
    "            )            \n",
    "    \n",
    "            if (global_frame_i - last_reload) >= RELOAD_THRESHOLD_FRAMES:\n",
    "                print(\"\\nLoading Latest Model\")\n",
    "                min_max = try_load(load_min_max)\n",
    "                policy = try_load(load_model)\n",
    "                last_reload = global_frame_i\n",
    "                time.sleep(SCREEN_DELAY_SECONDS)\n",
    "            global_frame_i += 1\n",
    "\n",
    "            if frame_i + 1 == MAX_MINUTES_PER_GAME * 60 * FPS:\n",
    "                print(\"\\nTime limit reached. Resetting.\")\n",
    "                time.sleep(SCREEN_DELAY_SECONDS)                \n",
    "            \n",
    "        hit = 0\n",
    "        miss = 0\n",
    "    \n",
    "        print(\"\\nLoading Latest Model. Starting New Game.\")\n",
    "        min_max = try_load(load_min_max)\n",
    "        policy = try_load(load_model)\n",
    "        last_reload = global_frame_i\n",
    "        time.sleep(SCREEN_DELAY_SECONDS)\n",
    "        \n",
    "except KeyboardInterrupt as e:\n",
    "    clear_output(wait=True)\n",
    "    _print_summary(\n",
    "        highest_score = highest_score, \n",
    "        score = p.score(), \n",
    "        hit = hit,\n",
    "        miss = miss,\n",
    "        frame_i = frame_i,\n",
    "        reload_frames = global_frame_i - last_reload,\n",
    "        reload_threshold_frames = RELOAD_THRESHOLD_FRAMES,\n",
    "        max_frames = MAX_MINUTES_PER_GAME * 60 * FPS\n",
    "    )\n",
    "    print(\"\\nExecution stopped by user\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
